{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "!pip install -e ./gym-env"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Obtaining file:///home/naman/courses/cs698/Midsem/gym-env\n",
      "Requirement already satisfied: gym in /home/naman/miniconda3/lib/python3.9/site-packages (from gym-env==1.0.0) (0.19.0)\n",
      "Requirement already satisfied: numpy>=1.18.0 in /home/naman/miniconda3/lib/python3.9/site-packages (from gym->gym-env==1.0.0) (1.20.3)\n",
      "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /home/naman/miniconda3/lib/python3.9/site-packages (from gym->gym-env==1.0.0) (1.6.0)\n",
      "Installing collected packages: gym-env\n",
      "  Attempting uninstall: gym-env\n",
      "    Found existing installation: gym-env 1.0.0\n",
      "    Uninstalling gym-env-1.0.0:\n",
      "      Successfully uninstalled gym-env-1.0.0\n",
      "  Running setup.py develop for gym-env\n",
      "Successfully installed gym-env-1.0.0\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import gym_env\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "rng = np.random.default_rng(0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# Representation of the MDP for RME\n",
    "P = {\n",
    "    0: { # state\n",
    "        0: [(0.9, 0, -0.04, False), (0.1, 1, -0.04, False)], # action: (p, s', r, f)\n",
    "        1: [(0.1, 0, -0.04, False), (0.1, 4, -0.04, False), (0.8, 1, -0.04, False)],\n",
    "        2: [(0.1, 0, -0.04, False), (0.1, 1, -0.04, False), (0.8, 4, -0.04, False)],\n",
    "        3: [(0.9, 0, -0.04, False), (0.1, 4, -0.04, False)]\n",
    "    },\n",
    "    1: {\n",
    "        0: [(0.1, 0, -0.04, False), (0.1, 2, -0.04, False), (0.8, 1, -0.04, False)],\n",
    "        1: [(0.2, 1, -0.04, False), (0.8, 2, -0.04, False)],\n",
    "        2: [(0.1, 0, -0.04, False), (0.1, 2, -0.04, False), (0.8, 1, -0.04, False)],\n",
    "        3: [(0.2, 1, -0.04, False), (0.8, 0, -0.04, False)],\n",
    "    },\n",
    "    2: {\n",
    "        0: [(0.1, 1, -0.04, False), (0.1, 3, 1, True), (0.8, 2, -0.04, False)],\n",
    "        1: [(0.1, 2, -0.04, False), (0.8, 3, 1, True), (0.1, 6, -0.04, False)],\n",
    "        2: [(0.1, 1, -0.04, False), (0.1, 3, 1, True), (0.8, 6, -0.04, False)],\n",
    "        3: [(0.1, 2, -0.04, False), (0.8, 1, -0.04, False), (0.1, 6, -0.04, False)],\n",
    "    },\n",
    "    4: {\n",
    "        0: [(0.8, 0, -0.04, False), (0.2, 4, -0.04, False)],\n",
    "        1: [(0.1, 0, -0.04, False), (0.1, 8, -0.04, False), (0.8, 4, -0.04, False)],\n",
    "        2: [(0.8, 8, -0.04, False), (0.2, 4, -0.04, False)],\n",
    "        3: [(0.1, 0, -0.04, False), (0.1, 8, -0.04, False), (0.8, 4, -0.04, False)],\n",
    "    },\n",
    "    6: {\n",
    "        0: [(0.1, 6, -0.04, False), (0.1, 7, -1, True), (0.8, 2, -0.04, False)],\n",
    "        1: [(0.1, 2, -0.04, False), (0.8, 7, -1, True), (0.1, 10, -0.04, False)],\n",
    "        2: [(0.1, 6, -0.04, False), (0.1, 7, -1, True), (0.8, 10, -0.04, False)],\n",
    "        3: [(0.1, 2, -0.04, False), (0.8, 6, -0.04, False), (0.1, 10, -0.04, False)],\n",
    "    },\n",
    "    8: {\n",
    "        0: [(0.8, 4, -0.04, False), (0.1, 8, -0.04, False), (0.1, 9, -0.04, False)],\n",
    "        1: [(0.1, 4, -0.04, False), (0.1, 8, -0.04, False), (0.8, 9, -0.04, False)],\n",
    "        2: [(0.9, 8, -0.04, False), (0.1, 9, -0.04, False)],\n",
    "        3: [(0.9, 8, -0.04, False), (0.1, 4, -0.04, False)]\n",
    "    },\n",
    "    9: {\n",
    "        0: [(0.1, 8, -0.04, False), (0.1, 10, -0.04, False), (0.8, 9, -0.04, False)],\n",
    "        1: [(0.2, 9, -0.04, False), (0.8, 10, -0.04, False)],\n",
    "        2: [(0.1, 8, -0.04, False), (0.1, 10, -0.04, False), (0.8, 9, -0.04, False)],\n",
    "        3: [(0.2, 9, -0.04, False), (0.8, 8, -0.04, False)],\n",
    "    },\n",
    "    10: {\n",
    "        0: [(0.1, 9, -0.04, False), (0.1, 11, -0.04, False), (0.8, 6, -0.04, False)],\n",
    "        1: [(0.1, 10, -0.04, False), (0.1, 6, -0.04, False), (0.8, 11, -0.04, False)],\n",
    "        2: [(0.1, 9, -0.04, False), (0.1, 11, -0.04, False), (0.8, 10, -0.04, False)],\n",
    "        3: [(0.1, 10, -0.04, False), (0.1, 6, -0.04, False), (0.8, 9, -0.04, False)],\n",
    "    },\n",
    "    11: {\n",
    "        0: [(0.1, 11, -0.04, False), (0.1, 10, -0.04, False), (0.8, 7, -1, True)],\n",
    "        1: [(0.1, 7, -1, True), (0.9, 11, -0.04, False)],\n",
    "        2: [(0.1, 10, -0.04, False), (0.9, 11, -0.04, False)],\n",
    "        3: [(0.1, 7, -1, True), (0.1, 11, -0.04, False), (0.8, 10, -0.04, False)],\n",
    "    }\n",
    "}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "def PolicyEvaluation(policy, P, gamma, theta):\n",
    "    v_old = np.zeros(12)\n",
    "    non_terminal = [0,1,2,4,6,8,9,10,11]\n",
    "    iters = 0\n",
    "    while True:\n",
    "        iters += 1\n",
    "        v_new = np.zeros(12)\n",
    "        for s in non_terminal:\n",
    "            for a in range(4):\n",
    "                temp = 0\n",
    "                for p, snew, r, f in P[s][a]:\n",
    "                    temp += p * (r + gamma * v_old[snew])\n",
    "                    # if f == True then v_old[snew] would be 0\n",
    "                v_new[s] += policy[s][a] * temp\n",
    "        if np.max(np.abs(v_new - v_old)) < theta:\n",
    "            break\n",
    "        v_old = v_new\n",
    "    print(f'PolicyEvaluation completed in {iters} iterations')\n",
    "    return v_new"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "policy = np.zeros((12, 4))\n",
    "non_terminal = [0,1,2,4,6,8,9,10,11]\n",
    "policy_actions = [3,3,3,3,1,3,3,1,0]\n",
    "for i in range(len(non_terminal)):\n",
    "    policy[non_terminal[i]][policy_actions[i]] = 1"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "def PolicyImprovement(v, P, gamma):\n",
    "    policy = np.zeros((12, 4))\n",
    "    q = np.zeros((12, 4))\n",
    "    for s in non_terminal:\n",
    "        for a in range(4):\n",
    "            for p, snew, r, f in P[s][a]:\n",
    "                q[s][a] += p * (r + gamma * v[snew])\n",
    "    \n",
    "    for s in non_terminal:\n",
    "        opt_action = np.argmax(q[s])\n",
    "        policy[s][opt_action] = 1\n",
    "    \n",
    "    return policy"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "def PolicyIteration(P, gamma, theta, policy=None):\n",
    "    iters = 0\n",
    "    while True:\n",
    "        iters += 1\n",
    "        policy_old = policy\n",
    "        v = PolicyEvaluation(policy, P, gamma, theta)\n",
    "        policy = PolicyImprovement(v, P, gamma)\n",
    "        if np.all(policy_old == policy):\n",
    "            break\n",
    "    \n",
    "    print(f'Converged to optimal policy in {iters} iterations')\n",
    "    return v, policy"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "opt_v, opt_policy = PolicyIteration(P, 0.99, 1e-10, policy)\n",
    "print(opt_v, opt_policy, sep='\\n')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "PolicyEvaluation completed in 1972 iterations\n",
      "PolicyEvaluation completed in 175 iterations\n",
      "PolicyEvaluation completed in 38 iterations\n",
      "PolicyEvaluation completed in 38 iterations\n",
      "Converged to optimal policy in 4 iterations\n",
      "[0.82442985 0.89286374 0.95464233 0.         0.76427487 0.\n",
      " 0.68820946 0.         0.69763948 0.63906542 0.60613373 0.38186228]\n",
      "[[0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "def ValueIteration(P, gamma, theta):\n",
    "    v = np.zeros(12)\n",
    "    non_terminal = [0,1,2,4,6,8,9,10,11]\n",
    "    iters = 0\n",
    "    while True:\n",
    "        iters += 1\n",
    "        q = np.zeros((12, 4))\n",
    "        for s in non_terminal:\n",
    "            for a in range(4):\n",
    "                for p, snew, r, f in P[s][a]:\n",
    "                    q[s][a] += p * (r + gamma * v[snew])\n",
    "        \n",
    "        if np.max(np.abs(v - np.max(q, axis=1))) < theta:\n",
    "            break\n",
    "        v = np.max(q, axis=1)\n",
    "    \n",
    "    policy = np.zeros((12, 4))\n",
    "    for s in non_terminal:\n",
    "        a = np.argmax(q[s])\n",
    "        policy[s][a] = 1\n",
    "    print(f'Converged to optimal policy in {iters} iterations')\n",
    "\n",
    "    return v, policy"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "opt_v, opt_policy = ValueIteration(P, 0.99, 1e-10)\n",
    "print(opt_v, opt_policy, sep='\\n')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Converged to optimal policy in 38 iterations\n",
      "[0.82442985 0.89286374 0.95464233 0.         0.76427487 0.\n",
      " 0.68820946 0.         0.69763948 0.63906542 0.60613373 0.38186228]\n",
      "[[0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "0d4d912fbce12427c141c51945610219055bd459fd76790fb88b88be3bedd6d6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}